<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=OPeqXG-QxW3ZD8BtmPikfA');.lst-kix_knoqbfimzbw5-3>li:before{content:"-  "}.lst-kix_knoqbfimzbw5-1>li:before{content:"-  "}.lst-kix_knoqbfimzbw5-5>li:before{content:"-  "}.lst-kix_knoqbfimzbw5-2>li:before{content:"-  "}.lst-kix_knoqbfimzbw5-6>li:before{content:"-  "}.lst-kix_knoqbfimzbw5-4>li:before{content:"-  "}ul.lst-kix_knoqbfimzbw5-7{list-style-type:none}ul.lst-kix_knoqbfimzbw5-6{list-style-type:none}ul.lst-kix_knoqbfimzbw5-8{list-style-type:none}.lst-kix_knoqbfimzbw5-7>li:before{content:"-  "}ul.lst-kix_knoqbfimzbw5-1{list-style-type:none}ul.lst-kix_knoqbfimzbw5-0{list-style-type:none}ul.lst-kix_knoqbfimzbw5-3{list-style-type:none}ul.lst-kix_knoqbfimzbw5-2{list-style-type:none}.lst-kix_knoqbfimzbw5-0>li:before{content:"-  "}ul.lst-kix_knoqbfimzbw5-5{list-style-type:none}.lst-kix_knoqbfimzbw5-8>li:before{content:"-  "}ul.lst-kix_knoqbfimzbw5-4{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c5{-webkit-text-decoration-skip:none;color:#000000;font-weight:700;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:11pt;font-family:"Arial";font-style:normal}.c19{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:20pt;font-family:"Arial";font-style:normal}.c8{background-color:#f1f3f4;color:#5f6368;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Roboto";font-style:normal}.c3{background-color:#ffffff;color:#212121;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Courier New";font-style:normal}.c10{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:15pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c13{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c16{background-color:#ffffff;font-size:10.5pt;font-family:"Courier New";color:#212121;font-weight:400}.c12{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;font-style:italic;text-decoration:underline}.c15{text-decoration-skip-ink:none;font-size:15pt;-webkit-text-decoration-skip:none;text-decoration:underline}.c20{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c18{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c6{margin-left:36pt;padding-left:0pt}.c11{padding:0;margin:0}.c9{color:inherit;text-decoration:inherit}.c7{font-weight:700}.c17{height:11pt}.c14{text-indent:36pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c18"><p class="c2"><span class="c1">Louis REMY</span></p><p class="c2"><span class="c1">Branavan SUBRAMANIAM</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span class="c7 c19">Rapport projet : Text Synthesis</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c7 c10">Lien du projet</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c20"><a class="c9" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1KteJZscMDhlQcBrCO2PGvx6akOaVDnGO?usp%3Dsharing&amp;sa=D&amp;ust=1607426984144000&amp;usg=AOvVaw39L3QBcMzZqZaqYRvimizH">https://colab.research.google.com/drive/1KteJZscMDhlQcBrCO2PGvx6akOaVDnGO?usp=sharing</a></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Nous avons ajout&eacute; l&rsquo;adresse suivante pour que vous puissiez acc&eacute;der au Colab&rsquo; : </span></p><p class="c2 c14"><span>christophe.rodrigues.bento@</span><span>gmail.com</span></p><p class="c0"><span class="c8"></span></p><p class="c2"><span class="c1">En cas de probl&egrave;me avec la connexion, contactez-nous sur l&rsquo;adresse devinci suivante :</span></p><p class="c2 c14"><span class="c1">louis.remy@edu.devinci.fr</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c10 c7">Cr&eacute;ation du dataframe</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Nous avons choisi d&rsquo;utiliser le format de dataframe de pandas pour manipuler notre jeu de donn&eacute;es. Depuis le .xml, nous avons choisi de nous concentrer uniquement sur les textes en fran&ccedil;ais puisqu&rsquo;ils sont bien plus nombreux que ceux en anglais. Pour nos analyses, nous avons cr&eacute;&eacute; les colonnes suivantes : Title, Date, Abstract, Corpus and Keyword. Voici un aper&ccedil;u de notre dataframe.</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 120.00px;"><img alt="" src="images/image27.png" style="width: 601.70px; height: 120.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c10 c7">Preprocessing</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Pour la phase de preprocessing, nous avons proc&eacute;d&eacute; comme suit. Premi&egrave;rement, nous enlevons toutes les apostrophes pr&eacute;sentes dans le texte (ex : &ldquo;l&rsquo;avion&rdquo; devient &ldquo;le avion&rdquo;). Deuxi&egrave;mement, nous enlevons les caract&egrave;res sp&eacute;ciaux (ex : &ldquo;(voir image)&rdquo; devient &ldquo;voir image&rdquo;. Troisi&egrave;mement, nous enlevons les accents (ex : &ldquo;&eacute;l&eacute;ment&rdquo; devient &ldquo;element&rdquo;)</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 117.33px;"><img alt="" src="images/image22.png" style="width: 601.70px; height: 117.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">La suite du preprocessing consiste en la d&eacute;tection des stopwords afin d&rsquo;all&eacute;ger le contenu des corpus pour ne garder uniquement les mots porteurs de sens.</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 114.67px;"><img alt="" src="images/image2.png" style="width: 601.70px; height: 114.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">La derni&egrave;re &eacute;tape du preprocessing consiste en l&rsquo;utilisation d&rsquo;un lemmatizer afin de conserver uniquement la racine de chaque mot. Pour cela, nous avons essay&eacute; deux lemmatizers diff&eacute;rents :</span></p><p class="c2"><span class="c1">French Lefff Lemmatizer =&gt; Ce dernier ne fonctionnait que pour les noms communs, lent</span></p><p class="c2"><span class="c1">Spacy =&gt; Fonctionne pour tous les types de mots mais est tr&egrave;s lent et ne reconna&icirc;t pas certains mots</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 113.33px;"><img alt="" src="images/image29.png" style="width: 601.70px; height: 113.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 117.33px;"><img alt="" src="images/image15.png" style="width: 601.70px; height: 117.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c1">Si l&rsquo;on observe le screenshot suivant, on peut observer des erreurs. On remarque que les verbes finissant par &ldquo;s&rdquo; sont consid&eacute;r&eacute;s comme des noms au pluriel (ex : &ldquo;consideron&rdquo;). On peut &eacute;galement remarquer que certains mots ne sont pas toujours trait&eacute;s de la m&ecirc;me mani&egrave;re (ex : &ldquo;grammair&rdquo; et &ldquo;grammaire&rdquo;).</span></p><p class="c2"><span class="c1">Une raison suppl&eacute;mentaire pour limiter l&rsquo;usage du lemmatizer est le temps d&rsquo;ex&eacute;cution qui est assez long (5 minutes) compar&eacute; aux quelques secondes des fonctions pr&eacute;c&eacute;dentes.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 460.00px; height: 166.00px;"><img alt="" src="images/image21.png" style="width: 460.00px; height: 166.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Pour finir, nous avons cr&eacute;&eacute; une version tokeniz&eacute;e de notre dataframe pour r&eacute;pondre aux besoins de certains des algorithmes que nous allons utiliser (dfToken).</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c7 c15">Critique du preprocessing</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Dans la partie pr&eacute;c&eacute;dente, nous avons parl&eacute; des probl&egrave;mes que nous avons rencontr&eacute; avec le lemmatizer. Or, cela nous semblait tout de m&ecirc;me &eacute;trange que la librairie ne fonctionne pas de la bonne mani&egrave;re. Nous avons donc fait quelques tests afin de mieux comprendre son fonctionnement.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Nous obtenons les r&eacute;sultats suivants :</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 248.11px; height: 126.50px;"><img alt="" src="images/image1.png" style="width: 248.11px; height: 126.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 256.07px; height: 128.58px;"><img alt="" src="images/image8.png" style="width: 256.07px; height: 128.58px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.50px; height: 139.88px;"><img alt="" src="images/image9.png" style="width: 250.50px; height: 139.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 255.79px; height: 140.53px;"><img alt="" src="images/image14.png" style="width: 255.79px; height: 140.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">On remarque que les accents et le contexte sont importants pour le lemmatizer. Cela lui permet de mieux identifier la nature des mots et donc leur racine.</span></p><p class="c2"><span class="c1">Pour prendre en compte cette information, nous avons donc simplement d&eacute;cid&eacute; de reprocess notre dataframe mais en utilisant le lemmatizer en premier, suivi du traitement des apostrophes, accents, caract&egrave;res sp&eacute;ciaux et stopwords.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">En refaisant toutes ces &eacute;tapes dans ce nouvel ordre, nous obtenons le r&eacute;sultat suivant :</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 117.33px;"><img alt="" src="images/image24.png" style="width: 601.70px; height: 117.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c10 c7">Analyse</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c5">Nuage de mots</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Librairie utilis&eacute;e : WordCloud</span></p><p class="c2"><span class="c1">Cette librairie est bas&eacute;e sur le calcul de la fr&eacute;quence de chaque mot du texte. Ces valeurs sont stock&eacute;es dans un dictionnaire pour ensuite &ecirc;tre affich&eacute;es via matplotlib.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c7 c13">Cette analyse &agrave; &eacute;t&eacute; faite avec l&rsquo;utilisation erron&eacute;e du lemmatizer.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Cette premi&egrave;re analyse consiste &agrave; observer les mots les plus prononc&eacute;s chaque ann&eacute;e dans les diff&eacute;rents articles scientifiques, le tout de mani&egrave;re visuelle.</span></p><p class="c2"><span class="c1">Lors de notre analyse des nuages de mots pour chaque ann&eacute;e, on remarque la pr&eacute;sence de mots &ldquo;parasites&rdquo; comme le mot &ldquo;avoir&rdquo; qui est pr&eacute;sent chaque ann&eacute;e. Pour pallier ce probl&egrave;me, on peut utiliser une librairie permettant de tagger les mots afin de se concentrer sur les noms communs uniquement par exemple.</span></p><p class="c2"><span class="c1">N&eacute;anmoins, cette approche ne nous semble pas int&eacute;ressante car elle ne se contente que de compter les occurrences des mots dans les textes pour ressortir ceux qui sont le plus prononc&eacute;s.</span></p><p class="c2"><span class="c1">De plus, en observant les r&eacute;sultats, on remarque que les mots que l&rsquo;on retrouve chaque ann&eacute;e ne varie pas beaucoup. On retrouve tr&egrave;s souvent les m&ecirc;mes mots comme &ldquo;corpus&rdquo;, &quot;syst&egrave;me&quot;, &ldquo;analyse&rdquo;, &ldquo;texte&rdquo;, &ldquo;traitement&rdquo; ou &ldquo;article&rdquo;.</span></p><p class="c2"><span class="c1">Voici une comparaison des trois premi&egrave;res ann&eacute;es du dataset avec les trois derni&egrave;res :</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 241.85px; height: 409.04px;"><img alt="" src="images/image20.png" style="width: 241.85px; height: 409.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 245.49px; height: 413.50px;"><img alt="" src="images/image10.png" style="width: 245.49px; height: 413.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c17"><span class="c1"></span></p><p class="c2"><span class="c1">Sur ces images, on peut tout de m&ecirc;me observer la forte pr&eacute;sence du terme &ldquo;analyse&rdquo; dans les premi&egrave;res ann&eacute;es et du terme &ldquo;r&eacute;sultat&rdquo; dans les derni&egrave;res. On peut supposer qu&rsquo;avec l&rsquo;avanc&eacute;e des technologies de Natural Language Processing, les mod&egrave;les utilis&eacute;s sont de plus en plus complexes et permettent de fournir des r&eacute;sultats plus concrets plut&ocirc;t qu&rsquo;une analyse sur les technologies existantes.</span></p><p class="c0"><span class="c1"></span></p><p class="c0 c14"><span class="c5"></span></p><p class="c0 c14"><span class="c5"></span></p><p class="c2 c14"><span class="c5">Diagramme en barre</span></p><p class="c0 c14"><span class="c5"></span></p><p class="c2"><span class="c1">Librairie utilis&eacute;e : Matplotlib</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c7">Cette analyse &agrave; &eacute;t&eacute; faite avec l&rsquo;utilisation erron&eacute;e du lemmatizer.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Pour tester une nouvelle approche, nous avons d&eacute;cid&eacute; d&rsquo;effectuer la m&ecirc;me op&eacute;ration, &agrave; savoir compter les occurrences, sur les abstracts du dataset mais d&rsquo;effectuer une repr&eacute;sentation diff&eacute;rente : un diagramme en barre.</span></p><p class="c2"><span class="c1">Le r&eacute;sultat obtenu sur l&rsquo;ensemble des abstracts est le suivant :</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 552.50px; height: 382.71px;"><img alt="" src="images/image6.png" style="width: 552.50px; height: 382.71px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c17"><span class="c1"></span></p><p class="c2"><span class="c1">On peut remarquer sur le diagramme ci-dessus que le verbe avoir est bien trop pr&eacute;sent dans le dataset. D&rsquo;autant plus que le retrait des accents en fran&ccedil;ais transforme les &ldquo;&agrave;&rdquo; en &ldquo;a&rdquo;, ce qui augmente leur occurrence artificiellement.</span></p><p class="c2"><span class="c1">On notera &eacute;galement la forte pr&eacute;sence de &quot;ce&quot; que nous n&rsquo;avions pas remarqu&eacute; pr&eacute;c&eacute;demment.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c5">Nuage de mots et diagramme en barre am&eacute;lior&eacute;s</span></p><p class="c0"><span class="c5"></span></p><p class="c2"><span class="c1">Afin de corriger ces probl&egrave;mes et d&rsquo;obtenir des r&eacute;sultats plus int&eacute;ressants, nous avons fait les choix suivants :</span></p><p class="c0"><span class="c1"></span></p><ul class="c11 lst-kix_knoqbfimzbw5-0 start"><li class="c2 c6"><span class="c1">Utiliser le lemmatizer comme pr&eacute;cis&eacute; dans la partie &ldquo;Critique du preprocessing&rdquo;</span></li><li class="c2 c6"><span class="c1">Nous allons &eacute;galement ajouter une &eacute;tape de preprocessing afin d&rsquo;enlever les mots de 3 lettres ou moins. Enlevant ainsi bon nombre de mots parasites qui ne sont pas consid&eacute;r&eacute; comme des stop words comme &ldquo;a&rdquo;</span></li><li class="c2 c6"><span class="c1">Enlever les verbes &ldquo;&ecirc;tre&rdquo; et &ldquo;avoir&rdquo; qui sont trop fr&eacute;quent</span></li></ul><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Avec ces r&egrave;gles, nous obtenons les r&eacute;sultats suivant :</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 592.50px; height: 118.11px;"><img alt="" src="images/image5.png" style="width: 592.50px; height: 118.11px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 239.88px; height: 404.50px;"><img alt="" src="images/image23.png" style="width: 239.88px; height: 404.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 243.92px; height: 409.50px;"><img alt="" src="images/image28.png" style="width: 243.92px; height: 409.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 454.65px; height: 316.14px;"><img alt="" src="images/image25.png" style="width: 454.65px; height: 316.14px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c1">On obtient ainsi des r&eacute;sultats plus significatifs car ayant des mots plus lourds de sens.</span></p><p class="c2"><span class="c1">Pour l&rsquo;interpr&eacute;tation de ces r&eacute;sultats, on peut relever la forte pr&eacute;sence du terme &ldquo;corpus&rdquo; dans cet ensemble d&rsquo;articles sur le diagramme en barres. Si l&rsquo;on combine cette information au fait que le mot corpus n&rsquo;est pas pr&eacute;sent dans les nuages de mots des premi&egrave;res ann&eacute;es, on peut en d&eacute;duire que l&rsquo;utilisation d&rsquo;un corpus de texte en guise de dataset est r&eacute;cent. Cela s&rsquo;explique tout naturellement avec l&rsquo;&eacute;volution de l&rsquo;informatique car on peut aujourd&rsquo;hui traiter rapidement plus de texte qu&rsquo;auparavant. La quantit&eacute; de donn&eacute;es &eacute;tant elle aussi plus &eacute;lev&eacute;e, il est plus ais&eacute; de trouver plus de contenu &agrave; analyser.</span></p><p class="c2"><span class="c1">La pr&eacute;sence du terme &ldquo;article&rdquo; n&rsquo;est &eacute;galement pas surprenante de part le fait de citer d&rsquo;autres articles lorsque l&rsquo;on &eacute;crit un papier de recherche.</span></p><p class="c2"><span class="c1">Quant aux autres mots, &ldquo;permettre&rdquo;, &ldquo;pr&eacute;senter&rdquo;, &ldquo;analyse&rdquo; et &ldquo;m&eacute;thode&rdquo; sont tous les quatre de mots qui se rapportent &agrave; la pr&eacute;sentation rigoureuse, il est donc normal de les retrouver dans le corpus.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c5">Comparaison Abstract/Keyword</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Voici les r&eacute;sultats des m&ecirc;mes analyse pour la colonne &ldquo;Keyword&rdquo;. Nous souhaitions faire cette comparaison afin de voir la justesse des keywords du corpus compar&eacute; &agrave; ceux trouv&eacute;s par notre analyse.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 241.85px; height: 402.01px;"><img alt="" src="images/image17.png" style="width: 241.85px; height: 402.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 244.91px; height: 409.01px;"><img alt="" src="images/image19.png" style="width: 244.91px; height: 409.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">On notera directement l&rsquo;absence de mots-cl&eacute;s pour les premi&egrave;res ann&eacute;es. Peut-&ecirc;tre &eacute;tait-ce une pratique qui n&rsquo;&eacute;tait pas encore appliqu&eacute;e. Pour l&rsquo;ann&eacute;e 1999, on remarquera &eacute;galement qu&rsquo;il n&rsquo;y a pas assez de mots-cl&eacute;s pour remplir le nuage compl&egrave;tement et aucun ne ressort. On peut donc supposer que chacun de ces mots n&rsquo;appara&icirc;t qu&rsquo;une fois en 1999.</span></p><p class="c2"><span class="c1">Regardons maintenant les ann&eacute;es 2016 &agrave; 2018. Si l&rsquo;on compare avec le r&eacute;sultat obtenu en &eacute;tudiant la colonne &ldquo;Abstract&rdquo;, on peut tout de suite remarquer que le contenu n&rsquo;est pas le m&ecirc;me.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Ainsi, on notera que le contenu de l&rsquo;Abstract contient davantage de mots faisant r&eacute;f&eacute;rence &agrave; l&rsquo;&eacute;tude et l&rsquo;interpr&eacute;tation des r&eacute;sultats. On voit que le but de ce paragraphe est de pr&eacute;senter les r&eacute;sultats au lecteur. En revanche, les mots-cl&eacute;s sont concentr&eacute;s sur les technologies et m&eacute;thodes utilis&eacute;es et le sujet d&rsquo;&eacute;tude de l&rsquo;article.</span></p><p class="c0"><span class="c1"></span></p><p class="c2 c14"><span class="c5">LDA</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">La prochaine analyse que nous avons souhait&eacute; effectu&eacute; est une LDA.</span></p><p class="c2"><span class="c1">Voici le r&eacute;sultat que nous avons obtenu sur l&rsquo;ensemble des abstracts avec les param&egrave;tres suivants : 5 sujet, 10 mots-cl&eacute;s par sujet</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 228.00px;"><img alt="" src="images/image30.png" style="width: 601.70px; height: 228.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c1">Ce r&eacute;sultat ne nous semble pas tr&egrave;s pertinent car les quatre sujets sont tr&egrave;s proches puisque l&rsquo;on retrouve les m&ecirc;mes mots-cl&eacute;s dans chacun d&rsquo;eux. Il serait peut-&ecirc;tre plus int&eacute;ressant de changer les param&egrave;tres en r&eacute;duisant le nombre de mots-cl&eacute;s par sujet.</span></p><p class="c2"><span class="c1">Cependant, avant de tester la LDA avec ces nouveaux param&egrave;tres, nous nous sommes aper&ccedil;u que si l&rsquo;on fait tourner l&rsquo;algorithme plusieurs fois, on retrouve des r&eacute;sultats diff&eacute;rents pour chaque sujet, comme le montre ce second screenshot.</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 493.66px; height: 183.59px;"><img alt="" src="images/image3.png" style="width: 493.66px; height: 183.59px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Une fois les param&egrave;tres chang&eacute;s &agrave; 10 sujet de 3 mots-cl&eacute;s chacun, et en faisant tourner le programme deux fois comme pr&eacute;c&eacute;demment, nous obtenons les r&eacute;sultats suivants :</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 203.00px; height: 421.00px;"><img alt="" src="images/image26.png" style="width: 203.00px; height: 421.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 200.00px; height: 419.00px;"><img alt="" src="images/image4.png" style="width: 200.00px; height: 419.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c5">LDA - Deuxi&egrave;me approche</span></p><p class="c0"><span class="c5"></span></p><p class="c2"><span class="c1">Afin d&rsquo;obtenir des r&eacute;sultats plus parlants et avec une meilleure interpr&eacute;tabilit&eacute;, nous voulions essayer d&rsquo;utiliser le mod&egrave;le de LDA vu en cours qui, en plus de fournir une liste de mots par sujet, fournit &eacute;galement l&rsquo;importance de chacun de ces mots.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Voici le r&eacute;sultat suite &agrave; un premier essai :</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 150.67px;"><img alt="" src="images/image7.png" style="width: 601.70px; height: 150.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">On remarque que le mot &ldquo;.&rdquo; est tr&egrave;s pr&eacute;sent dans chacun des sujets. Cela montre donc que notre dataframe tokenizer n&rsquo;est pas encore parfaitement preprocess.</span></p><p class="c2"><span class="c1">Nous avons donc fait une fonction permettant d&rsquo;enlever la ponctuation.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Suite &agrave; cette modification, nous obtenons le r&eacute;sultat suivant pour 4 sujet et 10 mots par sujet (r&eacute;sultat copi&eacute;-coll&eacute; du Notebook car le r&eacute;sultat est print sur une ligne comme le montre le screenshot pr&eacute;c&eacute;dent) :</span></p><p class="c2"><span class="c3">[(0, &#39;0.042*&quot;semantique&quot; + 0.026*&quot;reseau&quot; + 0.021*&quot;sequence&quot; + 0.020*&quot;traduction&quot; + 0.020*&quot;representation&quot; + 0.019*&quot;entite&quot; + 0.016*&quot;etiquetage&quot; + 0.014*&quot;systeme&quot; + 0.012*&quot;construction&quot; + 0.012*&quot;reconnaissance&quot;&#39;),</span></p><p class="c2"><span class="c3">(1, &#39;0.054*&quot;analyse&quot; + 0.031*&quot;syntaxique&quot; + 0.029*&quot;etude&quot; + 0.026*&quot;donnee&quot; + 0.024*&quot;partir&quot; + 0.020*&quot;lexical&quot; + 0.019*&quot;classification&quot; + 0.015*&quot;contexte&quot; + 0.013*&quot;medicament&quot; + 0.011*&quot;arabe&quot;&#39;),</span></p><p class="c2"><span class="c3">(2, &#39;0.067*&quot;automatique&quot; + 0.030*&quot;apprentissage&quot; + 0.026*&quot;hybride&quot; + 0.025*&quot;extraction&quot; + 0.024*&quot;expression&quot; + 0.021*&quot;modelisation&quot; + 0.021*&quot;polylexicale&quot; + 0.019*&quot;texte&quot; + 0.017*&quot;vers&quot; + 0.016*&quot;conversation&quot;&#39;),</span></p><p class="c2"><span class="c16">(3, &#39;0.042*&quot;corpus&quot; + 0.037*&quot;detection&quot; + 0.034*&quot;modele&quot; + 0.029*&quot;base&quot; + 0.025*&quot;evaluation&quot; + 0.024*&quot;neuronal&quot; + 0.023*&quot;annotation&quot; + 0.021*&quot;langue&quot; + 0.020*&quot;approche&quot; + 0.019*&quot;francais&quot;&#39;)]</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Testons &eacute;galement avec plus de sujets (10) afin de comparer la pertinence des r&eacute;sultats. On obtient :</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c3">[(0, &#39;0.075*&quot;base&quot; + 0.072*&quot;annotation&quot; + 0.069*&quot;approche&quot; + 0.048*&quot;relation&quot; + 0.033*&quot;baser&quot; + 0.020*&quot;annoter&quot; + 0.019*&quot;desambiguisationlexical&quot; + 0.019*&quot;outil&quot; + 0.014*&quot;vocabulaire&quot; + 0.014*&quot;acquisition&quot;&#39;),</span></p><p class="c2"><span class="c3">(1, &#39;0.061*&quot;modelisation&quot; + 0.052*&quot;contexte&quot; + 0.037*&quot;sens&quot; + 0.031*&quot;parole&quot; + 0.025*&quot;lexique&quot; + 0.024*&quot;ressource&quot; + 0.021*&quot;entrainement&quot; + 0.018*&quot;integration&quot; + 0.015*&quot;dependance&quot; + 0.014*&quot;developpemer&quot;&#39;),</span></p><p class="c2"><span class="c3">(2, &#39;0.151*&quot;automatique&quot; + 0.046*&quot;texte&quot; + 0.039*&quot;expression&quot; + 0.035*&quot;polylexicale&quot; + 0.030*&quot;.&quot; + 0.028*&quot;systeme&quot; + 0.022*&quot;grace&quot; + 0.018*&quot;type&quot; + 0.016*&quot;morphologique&quot; + 0.016*&quot;apport&quot;&#39;),</span></p><p class="c2"><span class="c3">(3, &#39;0.074*&quot;apprentissage&quot; + 0.072*&quot;modele&quot; + 0.066*&quot;evaluation&quot; + 0.030*&quot;plongement&quot; + 0.028*&quot;superviser&quot; + 0.024*&quot;morpho&quot; + 0.024*&quot;adaptation&quot; + 0.023*&quot;methode&quot; + 0.018*&quot;application&quot; + 0.017*&quot;extrinseque&quot;&#39;),</span></p><p class="c2"><span class="c3">(4, &#39;0.066*&quot;reseau&quot; + 0.047*&quot;vers&quot; + 0.047*&quot;entite&quot; + 0.037*&quot;discours&quot; + 0.028*&quot;resolution&quot; + 0.023*&quot;analyseur&quot; + 0.020*&quot;nommer&quot; + 0.016*&quot;generation&quot; + 0.016*&quot;party&quot; + 0.015*&quot;alsacien&quot;&#39;),</span></p><p class="c2"><span class="c3">(5, &#39;0.092*&quot;semantique&quot; + 0.064*&quot;langue&quot; + 0.064*&quot;etude&quot; + 0.047*&quot;partir&quot; + 0.045*&quot;representation&quot; + 0.041*&quot;donnee&quot; + 0.025*&quot;construction&quot; + 0.023*&quot;utilisation&quot; + 0.016*&quot;lexico&quot; + 0.015*&quot;impact&quot;&#39;),</span></p><p class="c2"><span class="c3">(6, &#39;0.115*&quot;analyse&quot; + 0.072*&quot;syntaxique&quot; + 0.044*&quot;conversation&quot; + 0.038*&quot;classification&quot; + 0.033*&quot;medicament&quot; + 0.022*&quot;arabe&quot; + 0.021*&quot;dialogue&quot; + 0.016*&quot;detecter&quot; + 0.015*&quot;reponse&quot; + 0.015*&quot;reel&quot;&#39;),</span></p><p class="c2"><span class="c3">(7, &#39;0.070*&quot;neuronal&quot; + 0.066*&quot;enfrancais&quot; + 0.064*&quot;hybride&quot; + 0.051*&quot;traduction&quot; + 0.038*&quot;etiquetage&quot; + 0.038*&quot;sequence&quot; + 0.034*&quot;reconnaissance&quot; + 0.026*&quot;troismonde&quot; + 0.026*&quot;meilleur&quot; + 0.021*&quot;similarite&quot;&#39;),</span></p><p class="c2"><span class="c3">(8, &#39;0.124*&quot;corpus&quot; + 0.102*&quot;detection&quot; + 0.049*&quot;francais&quot; + 0.026*&quot;distributionnel&quot; + 0.024*&quot;sentiment&quot; + 0.020*&quot;entre&quot; + 0.019*&quot;terme&quot; + 0.018*&quot;libre&quot; + 0.018*&quot;alignement&quot; + 0.017*&quot;defrancais&quot;&#39;),</span></p><p class="c2"><span class="c16">(9, &#39;0.070*&quot;extraction&quot; + 0.046*&quot;lexical&quot; + 0.029*&quot;exemple&quot; + 0.028*&quot;document&quot; + 0.025*&quot;recherche&quot; + 0.022*&quot;interaction&quot; + 0.021*&quot;desambiguisation&quot; + 0.019*&quot;manuscritancien&quot; + 0.018*&quot;deinformation&quot; + 0.017*&quot;information&quot;&#39;)]</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c5">LDA - Affichage</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Librairie utilis&eacute;e : pyLDAvis</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Afin de mieux comprendre l&rsquo;analyse LDA, nous avons essay&eacute; d&rsquo;utiliser une librairie permettant d&rsquo;afficher les r&eacute;sultats. Comme le montre l&rsquo;exemple ci dessous, cela permet d&rsquo;obtenir un aper&ccedil;u de la distance entre chaque sujet (&agrave; gauche) ainsi qu&rsquo;un aper&ccedil;u des sujets les plus pr&eacute;sent dans le corpus (&agrave; droite)</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 283.58px; height: 184.70px;"><img alt="" src="images/image18.png" style="width: 283.58px; height: 184.70px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Malheureusement, nous n&rsquo;avons pas r&eacute;ussi &agrave; faire fonctionner cette librairie. Vous pouvez retrouver nos tentatives dans le notebook.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c5">TSNE</span></p><p class="c0"><span class="c5"></span></p><p class="c2"><span class="c1">Librairie utilis&eacute;e : TSNE de sklearn</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Pour notre prochaine analyse, nous avons choisi de regarder les liens et les rapprochements qu&rsquo;il y a entre les mots de ce corpus, notamment, ceux que l&rsquo;on retrouve dans les mots les plus utilis&eacute;s (cf Diagramme en barres).</span></p><p class="c2"><span class="c1">Une telle &eacute;tude nous permettra d&rsquo;identifier les th&egrave;mes les plus abord&eacute;s dans ce corpus et d&rsquo;observer la coh&eacute;rence entre ce dataset et ce &agrave; quoi on peut s&rsquo;attendre d&rsquo;un article scientifique.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Pour notre premier test, nous avons choisi une perplexit&eacute; de 40 avec 2500 it&eacute;rations. Nous obtenons le r&eacute;sultat suivant :</span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 404.45px; height: 391.31px;"><img alt="" src="images/image16.png" style="width: 404.45px; height: 391.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Pour interpr&eacute;ter le r&eacute;sultat de ce TSNE, il faut observer la distance relative entre les points et non leur position comme pour une ACP. Il ne faut &eacute;galement pas s&rsquo;attarder sur la taille des clusters, ni sur la distance entre les clusters.</span></p><p class="c2"><span class="c1">Cependant, nous ne remarquons pas sp&eacute;cialement de cluster particulier sur ce graphique. Avant de tester avec d&rsquo;autres param&egrave;tres, nous voulions tout de m&ecirc;me essayer d&rsquo;observer les mots les plus fr&eacute;quents dans ce corpus. Vous pouvez observer ces r&eacute;sultats sur l&rsquo;image suivante.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">On remarque que ces mots sont assez proches l&rsquo;un de l&rsquo;autre sous forme de petit groupe de mots. Outre le fait qu&rsquo;il s&rsquo;agisse d&rsquo;un lexique que l&rsquo;on peut s&rsquo;attendre &agrave; retrouver dans des articles scientifiques, ces mots apportent des pr&eacute;cisions sur le contenu du corpus. Voici quelques explications pour certains de ces mots qui permettent d&rsquo;appr&eacute;hender le contenu de ce corpus :</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 438.81px; height: 429.50px;"><img alt="" src="images/image13.png" style="width: 438.81px; height: 429.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c12">Article</span><span class="c1">&nbsp;: On remarque que le mot article est proche des mots &ldquo;outil&rdquo;, &ldquo;cadre&rdquo;, &ldquo;information&rdquo; et &ldquo;forme&rdquo;. Cela montre que les occurrences du mot &ldquo;article&rdquo; de ce corpus ne font pas r&eacute;f&eacute;rence &agrave; eux-m&ecirc;me mais plut&ocirc;t &agrave; d&rsquo;autres articles qui sont cit&eacute;s comme source pour &eacute;tayer le contenu (citation, bibliographie, comparaison, exemple&hellip;)</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c12">Syst&egrave;me, langue, automatique</span><span class="c1">&nbsp;: Ces trois mots sont tr&egrave;s proches l&rsquo;un de l&rsquo;autre, cela peut donc sugg&eacute;rer que les articles de ce corpus ont pour but d&rsquo;automatiser le langage le plus possible. Si l&rsquo;on regarde les sujets g&eacute;n&eacute;r&eacute;s par l&rsquo;analyse LDA, on peut confirmer ce th&egrave;me r&eacute;current. On pourrait le d&eacute;fini tel que &ldquo;ces articles proposent un syst&egrave;me permettant d&rsquo;automatiser le langage&rdquo;</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c12">Analyse</span><span class="c1">&nbsp;: Le mot &ldquo;analyse&rdquo; est tr&egrave;s proche du mot &ldquo;syntaxique&rdquo;, ce qui nous montre clairement le sujet de l&rsquo;analyse.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c12">Pr&eacute;senter, m&eacute;thode, corpus, texte</span><span class="c1">&nbsp;: On peut supposer que ce cluster repr&eacute;sente l&rsquo;approche qu&rsquo;ont ces articles scientifiques.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Afin de mieux comprendre les r&eacute;sultats et surtout l&rsquo;impact des hyper param&egrave;tres de l&rsquo;analyse TSNE (notamment &ldquo;perplexity&rdquo;), nous avons essay&eacute; une autre valeur : 5. Nous avons &eacute;galement augment&eacute; le nombre d&rsquo;it&eacute;rations (2500 &agrave; 5000). Nous obtenons le r&eacute;sultat suivant :</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 325.65px; height: 310.36px;"><img alt="" src="images/image11.png" style="width: 325.65px; height: 310.36px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sur cette image, on remarque d&eacute;j&agrave; que l&rsquo;on peut mieux identifier les clusters. Nous avons fait quelques recherches et il semblerait qu&rsquo;augmenter le nombre d&rsquo;it&eacute;rations permet de mieux d&eacute;finir les clusters, ce que l&rsquo;on voit bien si l&rsquo;on compare cette image aux pr&eacute;c&eacute;dentes.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Si l&rsquo;on observe &eacute;galement les mots qui sont parmi les plus repr&eacute;sent&eacute;s sur cette nouvelle visualisation du TSNE, on remarque que chaque cluster contient au moins un de ces mots. On peut alors supposer que ces mots, &eacute;tant les plus fr&eacute;quents, et donc potentiellement les plus importants, sont ceux utilis&eacute;s par l&rsquo;algorithme TSNE pour former des clusters.</span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 325.03px; height: 314.94px;"><img alt="" src="images/image12.png" style="width: 325.03px; height: 314.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></body></html>